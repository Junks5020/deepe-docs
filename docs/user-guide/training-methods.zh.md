# 训练方法管理

**训练方法管理**模块允许注册和配置 DeepExtension 中用于微调的大语言模型策略。这些策略可在[模型训练](model-training.zh.md)模块中选择，并定义了如何将基础模型适配到特定领域的任务中。

支持的训练方法类型包括：

- **SFT**（监督式微调）
- **PEFT**（参数高效微调，例如 LoRA、Adapters）
- **PPO**、**GRPO** 等基于强化学习的方法
- **VL** 针对图生文模型的训练
- **SD** 对于生图模型的训练，底层采用SimpleTuner的开源框架实现训练

---

## 总览

在主页面的**训练方法管理**列表中，列出了所有已注册的训练方法。这些方法将在创建新训练任务时于[模型训练](model-training.zh.md)界面中展示。

如果您是开发者或平台维护者，请参考**开发者指南**，了解如何实现自己的训练逻辑并将其接入 DeepExtension 平台。


---

## 添加新训练方法

本节介绍在系统中添加新训练方法的完整流程。

### 操作步骤

1. 点击界面中的 **“添加新方法”** 按钮。
2. 在弹出表单中，填写以下必填信息：

### 配置字段说明

#### 基础信息
- **训练名称**：为新训练方法设定一个唯一标识名称。

- **训练类型**：从下拉列表中选择对应的训练类型：

    - `chat`：纯文本对话模型训练

    - `embedding`：文本解析模型训练  

    - `vision-language`：图生文多模态模型训练
    
    - `image-generation`：图像生成模型训练

#### 生命周期配置

- **生命周期**：选择模型的生命周期路径。

    - *详细说明请参阅：[模型生命周期管理](../tutorials/tutorial-process-dependency.zh.md)*

    - **不同生命周期选项对应的配置要求**：


| 生命周期选项 | 必须配置项 | 可选配置项 |
|-------------|-----------|-----------|
| **定制模型** | 训练代码文件、训练环境 | 定制模型推理功能<br>• 启用时需配置：推理代码文件、conda环境名称 |
| **完整模型** | 保存代码文件、训练环境 | 完整模型推理功能<br>• 启用时需配置：推理代码文件、conda环境名称 |
| **上线模型** | 部署环境选择 | • 自定义部署环境需配置：部署环境代码文件、conda环境名称 |

#### Python文件配置
配置各阶段执行的实际Python文件及运行环境：

  - **`training`**：训练阶段使用的Python文件和conda环境

  - **`saving`**：模型保存阶段使用的Python文件和conda环境 

  - **`inference-customized`**：定制模型推理使用的Python文件和conda环境

  - **`inference-complete`**：完整模型推理使用的Python文件和conda环境

**提示**：带 * 的字段为必填项。请根据所选生命周期路径，完成相应阶段的文件配置。

---


> **注意**：仅商业用户可添加新的训练方法。 非商业用户建议使用内置的 `custom01` 和 `custom02` 方法，这两个模板也可定制，并可作为用户扩展逻辑的起点。具体实现请参阅**开发者指南**。

---

## 删除训练方法

要删除某个训练方法：

- 点击目标训练方法旁的 **“删除”** 按钮
- 删除后该方法将不再出现在[模型训练](model-training.zh.md)界面的可选方法列表中

> **注意**：为了保障系统稳定性和流程完整性，删除功能仅对商业用户开放。

---

## 预安装的训练方法

为帮助用户快速入门，DeepExtension 根据操作系统预装了若干训练方法示例。

### CUDA（Linux 或者 Windows (通过 WSL)）用户

- **GRPO-Demo**：用于逻辑型微调任务的 GRPO（引导式强化学习）示例方法
- **SFT-Demo**：适用于小规模任务的监督式微调示例
- **Custom01** 和 **Custom02**：可由开发者扩展的完全可定制模板

### macOS 用户（适用于 MLX）

- **MLX-Demo**：基于 Apple MLX 框架的演示训练方法，专为 M 系列芯片优化
- **Custom01** 和 **Custom02**：同样提供可扩展的自定义模板

> GRPO-Demo、SFT-Demo 和 MLX-Demo 均已配置完毕，并附带示例数据集，可帮助立即上手 DeepExtension 的训练功能。

> **Custom01** 和 **Custom02** 面向具有 AI/ML 背景的开发者设计，详见[实现自定义训练逻辑](../developer/implement-own-ai-training.zh.md)。

---

*DeepExtension — 灵活的训练策略管理，是实现高效微调的第一步*